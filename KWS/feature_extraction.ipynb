{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c67f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import librosa\n",
    "#import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "#import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de795d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\samui\\anaconda3\\envs\\tinyml\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.5\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "946382ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60742eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU configuration successful.\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set only the first GPU as visible\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        # Allow memory growth to allocate memory dynamically on the GPU\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"GPU configuration successful.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e4e7501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'on': 0, 'off': 1, 'up': 2, 'down': 3}\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = \"data/raw_data/\"\n",
    "\n",
    "kws_list=['on','off','up','down']\n",
    "lang_index_dict={kws_list[i]:i for i in range(len(kws_list))}\n",
    "print(lang_index_dict)\n",
    "\n",
    "JSON_PATH = \"data_new.json\"\n",
    "sr=16000\n",
    "SAMPLES_TO_CONSIDER = 16000 # 1 sec. of audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88255174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define Hamming window function\n",
    "# def hamming_window(length):\n",
    "#     return 0.54 - 0.46 * np.cos(2 * np.pi * np.arange(length) / (length - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12bbb02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 'down'\n",
      "data/raw_data/down\\00b01445_nohash_0.wav: down- 0 \n",
      "data/raw_data/down\\00b01445_nohash_1.wav: down- 0 \n",
      "data/raw_data/down\\00f0204f_nohash_0.wav: down- 0 \n",
      "data/raw_data/down\\0a2b400e_nohash_0.wav: down- 0 \n",
      "data/raw_data/down\\0a2b400e_nohash_1.wav: down- 0 \n",
      "data/raw_data/down\\0a2b400e_nohash_2.wav: down- 0 \n",
      "\n",
      "Processing: 'off'\n",
      "data/raw_data/off\\0a196374_nohash_0.wav: off- 1 \n",
      "data/raw_data/off\\0a2b400e_nohash_2.wav: off- 1 \n",
      "data/raw_data/off\\0a2b400e_nohash_3.wav: off- 1 \n",
      "data/raw_data/off\\0a2b400e_nohash_4.wav: off- 1 \n",
      "data/raw_data/off\\0a5636ca_nohash_0.wav: off- 1 \n",
      "data/raw_data/off\\0a5636ca_nohash_1.wav: off- 1 \n",
      "\n",
      "Processing: 'on'\n",
      "data/raw_data/on\\00b01445_nohash_0.wav: on- 2 \n",
      "data/raw_data/on\\0a2b400e_nohash_0.wav: on- 2 \n",
      "data/raw_data/on\\0a2b400e_nohash_1.wav: on- 2 \n",
      "data/raw_data/on\\0a7c2a8d_nohash_0.wav: on- 2 \n",
      "data/raw_data/on\\0a9f9af7_nohash_0.wav: on- 2 \n",
      "data/raw_data/on\\0a9f9af7_nohash_1.wav: on- 2 \n",
      "\n",
      "Processing: 'up'\n",
      "data/raw_data/up\\00b01445_nohash_0.wav: up- 3 \n",
      "data/raw_data/up\\00b01445_nohash_1.wav: up- 3 \n",
      "data/raw_data/up\\0a2b400e_nohash_0.wav: up- 3 \n",
      "data/raw_data/up\\0a2b400e_nohash_1.wav: up- 3 \n",
      "data/raw_data/up\\0a2b400e_nohash_2.wav: up- 3 \n",
      "data/raw_data/up\\0a2b400e_nohash_3.wav: up- 3 \n"
     ]
    }
   ],
   "source": [
    "frame_length = int(sr * ( 32 / 1000))\n",
    "hop_length = int(sr * ( 16 / 1000))\n",
    "\n",
    "data = {\n",
    "        \"mapping\": [],\n",
    "        \"labels\": [],\n",
    "        \"MFCCs\": [],\n",
    "        \"files\": []\n",
    "    }\n",
    "\n",
    "j=0\n",
    "# loop through all sub-dirs\n",
    "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(DATASET_PATH)):\n",
    "\n",
    "    # ensure we're at sub-folder level\n",
    "    if dirpath is not DATASET_PATH:\n",
    "\n",
    "        # save label (i.e., sub-folder name) in the mapping\n",
    "        label = dirpath.split(\"/\")[-1]\n",
    "        \n",
    "        if label in kws_list:\n",
    "            j = j+1\n",
    "            print(\"\\nProcessing: '{}'\".format(label))\n",
    "            # process all audio files in sub-dir and store MFCCs\n",
    "            for f in filenames:\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                #print(file_path)\n",
    "                # load audio file and slice it to ensure length consistency among different files\n",
    "                signal,_=librosa.load(file_path,sr=sr)\n",
    "                if len(signal)>=SAMPLES_TO_CONSIDER:\n",
    "                    signal=signal[0:SAMPLES_TO_CONSIDER]\n",
    "                else:\n",
    "                    npad = SAMPLES_TO_CONSIDER - len(signal)\n",
    "                    signal=np.pad(signal, pad_width=npad, mode='constant', constant_values=0)[npad:]\n",
    "\n",
    "                signal=signal.astype(np.float32)\n",
    "                \n",
    "                f=librosa.feature.mfcc(y=signal, sr=sr, win_length = frame_length,hop_length=hop_length,n_mfcc=13, n_fft = frame_length,center=0)\n",
    "                #print(f.shape)\n",
    "                #print(\"{}- {}\".format(\">=\" , f.shape))\n",
    "                # store data for analysed track\n",
    "                data[\"labels\"].append(j-1)\n",
    "                data[\"MFCCs\"].append(f.T.tolist())\n",
    "                data[\"files\"].append(file_path)\n",
    "                print(\"{}: {}- {} \".format(file_path, label , j-1))\n",
    "                \n",
    "    # save data in json file\n",
    "    with open(JSON_PATH, \"w\") as fp:\n",
    "        json.dump(data, fp, indent= 4)   #### indent= 4\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15a41c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tinyml]",
   "language": "python",
   "name": "conda-env-tinyml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

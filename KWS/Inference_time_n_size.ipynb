{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Change runtime type --> GPU**\n",
        "\n",
        "**Mount drive**"
      ],
      "metadata": {
        "id": "AC6mNFxj3WQe"
      },
      "id": "AC6mNFxj3WQe"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLlOvCMe3asc",
        "outputId": "7b263afb-9009-4140-8df6-e5fb46a9c8a4"
      },
      "id": "sLlOvCMe3asc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50b94649",
      "metadata": {
        "id": "50b94649"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce20b155",
      "metadata": {
        "id": "ce20b155"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "tf.config.experimental.set_memory_growth(gpus[0], True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e5a82a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53e5a82a",
        "outputId": "a546ba23-7a44-4eb1-8e7b-1b2e53ab844c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU configuration successful.\n"
          ]
        }
      ],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Set only the first GPU as visible\n",
        "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "        # Allow memory growth to allocate memory dynamically on the GPU\n",
        "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "        print(\"GPU configuration successful.\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"No GPU detected.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ad7b340",
      "metadata": {
        "id": "6ad7b340"
      },
      "outputs": [],
      "source": [
        "file_path = \"drive/MyDrive/tinyML_projects/KWS/left.wav\"             #  left.wav\n",
        "SAMPLES_TO_CONSIDER = 16000\n",
        "sr = 16000\n",
        "mapping = [ 'background_noise','unknown',  'down']\n",
        "\n",
        "frame_length = int(sr * ( 32 / 1000))\n",
        "hop_length = int(sr * ( 16 / 1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbc0797e",
      "metadata": {
        "id": "fbc0797e"
      },
      "source": [
        "# kearas model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fda2108d",
      "metadata": {
        "id": "fda2108d"
      },
      "outputs": [],
      "source": [
        "#SAVED_MODEL_PATH = \"/home/soumen/Soumen/model/KWS/project_1/2D_CNN.keras\"\n",
        "#SAVED_MODEL_PATH = \"/home/soumen/Soumen/model/KWS/project_1/1D_CNN.keras\"\n",
        "SAVED_MODEL_PATH = \"drive/MyDrive/tinyML_projects/1D_CNN.keras\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f9aa74a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f9aa74a",
        "outputId": "e0dd65c5-5d50-4ab9-a995-beb119712d1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
            "[0.212 0.576 0.212]\n",
            "unknown\n",
            "Time taken for prediction: 0.2586708068847656 seconds\n",
            "Model size: 44295470 bytes\n",
            "Model size: 43257.29 KB\n",
            "Model size: 42.24 MB\n"
          ]
        }
      ],
      "source": [
        "signal, sample_rate = librosa.load(file_path)\n",
        "#print(sample_rate)\n",
        "if len(signal)>=SAMPLES_TO_CONSIDER:\n",
        "    signal=signal[0:SAMPLES_TO_CONSIDER]\n",
        "else:\n",
        "    npad = SAMPLES_TO_CONSIDER - len(signal)\n",
        "    signal=np.pad(signal, pad_width=npad, mode='constant', constant_values=0)[npad:]\n",
        "\n",
        "signal=signal.astype(np.float32)\n",
        "f=librosa.feature.mfcc(y=signal, sr=sr, win_length = frame_length,hop_length=hop_length,n_mfcc=13, n_fft = frame_length,center=0)\n",
        "\n",
        "f=f.T\n",
        "###### For 1-D CNN #######\n",
        "f = f.reshape(1,f.shape[0],f.shape[1])\n",
        "#print(f.shape)\n",
        "##########################\n",
        "###### For 2-D CNN #######\n",
        "# f = f.reshape(1,f.shape[0],f.shape[1],1)\n",
        "# print(f.shape)\n",
        "##########################\n",
        "#load the model\n",
        "model = tf.keras.models.load_model(SAVED_MODEL_PATH)\n",
        "\n",
        "start_time = time.time()\n",
        "predictions = model.predict(f)\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the time taken for the prediction\n",
        "prediction_time = end_time - start_time\n",
        "\n",
        "#Posterior Handling\n",
        "np.set_printoptions(precision=3)\n",
        "scores = np.ravel(predictions)\n",
        "output=softmax(scores)\n",
        "print(output)\n",
        "predicted_index = np.argmax(output, axis=0)\n",
        "print(mapping[predicted_index])\n",
        "\n",
        "print(f\"Time taken for prediction: {prediction_time} seconds\")\n",
        "\n",
        "# Get the size of the model in bytes\n",
        "model_size_bytes = os.path.getsize(SAVED_MODEL_PATH)\n",
        "\n",
        "# Convert to kilobytes (KB) and megabytes (MB)\n",
        "model_size_kb = model_size_bytes / 1024\n",
        "model_size_mb = model_size_kb / 1024\n",
        "\n",
        "print(f\"Model size: {model_size_bytes} bytes\")\n",
        "print(f\"Model size: {model_size_kb:.2f} KB\")\n",
        "print(f\"Model size: {model_size_mb:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import lite\n",
        "from tensorflow.keras import models"
      ],
      "metadata": {
        "id": "IVNKJWGi6c_s"
      },
      "id": "IVNKJWGi6c_s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#############  2D_CNN  #############\n",
        "#keras_model_filename = '/home/soumen/Soumen/model/KWS/project_1/2D_CNN.keras'\n",
        "#tflite_filename = '/home/soumen/Soumen/model/KWS/project_1/2D_CNN.tflite'\n",
        "\n",
        "#############  1D_CNN  #############\n",
        "keras_model_filename = \"drive/MyDrive/tinyML_projects/1D_CNN.keras\"\n",
        "tflite_filename = 'drive/MyDrive/tinyML_projects/1D_CNN.tflite'\n",
        "\n",
        "#############  TCN  #############\n",
        "#keras_model_filename = '/home/soumen/Soumen/model/KWS/project_1/TCN.keras'\n",
        "#flite_filename = '/home/soumen/Soumen/model/KWS/project_1/TCN.tflite'"
      ],
      "metadata": {
        "id": "gyNtVepI6W2P"
      },
      "id": "gyNtVepI6W2P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model to TF Lite model\n",
        "model = models.load_model(keras_model_filename)\n",
        "converter = lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "open(tflite_filename, 'wb').write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mudYujNz7E28",
        "outputId": "94799a1d-65e4-4391-80cc-9d310ae255ff"
      },
      "id": "mudYujNz7E28",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpk976137q'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 61, 13), dtype=tf.float32, name='input_layer_2')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  135466570835648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135466570515728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135466543288336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135466543295552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135466543300304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135466543582720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135466543587472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135466543593104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135466543593632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135466543594160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135466543761712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135466543765232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14759156"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a59e0baa",
      "metadata": {
        "id": "a59e0baa"
      },
      "source": [
        "# TFLite model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc840bd3",
      "metadata": {
        "id": "bc840bd3"
      },
      "outputs": [],
      "source": [
        "#SAVED_MODEL_PATH = \"/home/soumen/Soumen/model/KWS/project_1/2D_CNN.tflite\"\n",
        "SAVED_MODEL_PATH = \"drive/MyDrive/tinyML_projects/1D_CNN.tflite\"\n",
        "#SAVED_MODEL_PATH = \"/home/soumen/Soumen/model/KWS/project_1/TCN.tflite\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f8b8ee0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f8b8ee0",
        "outputId": "8157db60-8593-4144-aaec-41ec8cf86c4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.212 0.576 0.212]\n",
            "background_noise\n",
            "Time taken for prediction: 0.003979206085205078 seconds\n",
            "Model size: 14759156 bytes\n",
            "Model size: 14413.24 KB\n",
            "Model size: 14.08 MB\n"
          ]
        }
      ],
      "source": [
        "# Load the audio file\n",
        "signal, sample_rate = librosa.load(file_path, sr=None)  # Use sr=None to preserve the original sampling rate\n",
        "\n",
        "# Ensure the signal length matches SAMPLES_TO_CONSIDER\n",
        "if len(signal) >= SAMPLES_TO_CONSIDER:\n",
        "    signal = signal[0:SAMPLES_TO_CONSIDER]\n",
        "else:\n",
        "    npad = SAMPLES_TO_CONSIDER - len(signal)\n",
        "    signal = np.pad(signal, (0, npad), mode='constant', constant_values=0)\n",
        "\n",
        "# Convert signal to float32\n",
        "signal = signal.astype(np.float32)\n",
        "\n",
        "# Extract MFCC features\n",
        "f = librosa.feature.mfcc(y=signal, sr=sample_rate, win_length=frame_length,\n",
        "                         hop_length=hop_length, n_mfcc=13, n_fft=frame_length, center=False)\n",
        "\n",
        "# Transpose the MFCC matrix\n",
        "f = f.T\n",
        "\n",
        "# Reshape for CNN input\n",
        "###### For 1-D CNN #######\n",
        "f = f.reshape(1, f.shape[0], f.shape[1])\n",
        "\n",
        "###### For 2-D CNN #######\n",
        "# f = f.reshape(1, f.shape[0], f.shape[1], 1)\n",
        "\n",
        "# Load the TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=SAVED_MODEL_PATH)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Set the input tensor\n",
        "interpreter.set_tensor(input_details[0]['index'], f)\n",
        "\n",
        "# Measure the time taken for prediction\n",
        "start_time = time.time()\n",
        "interpreter.invoke()\n",
        "end_time = time.time()\n",
        "\n",
        "# Get the output tensor\n",
        "predictions = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "# Calculate the time taken for the prediction\n",
        "prediction_time = end_time - start_time\n",
        "\n",
        "# Handle the output predictions\n",
        "np.set_printoptions(precision=3)\n",
        "scores = np.ravel(predictions)\n",
        "output = softmax(scores)\n",
        "print(output)\n",
        "\n",
        "# Determine the predicted class\n",
        "predicted_index = np.argmax(output, axis=0)\n",
        "print(mapping[predicted_index])\n",
        "\n",
        "print(f\"Time taken for prediction: {prediction_time} seconds\")\n",
        "\n",
        "\n",
        "# Get the size of the model in bytes\n",
        "model_size_bytes = os.path.getsize(SAVED_MODEL_PATH)\n",
        "\n",
        "# Convert to kilobytes (KB) and megabytes (MB)\n",
        "model_size_kb = model_size_bytes / 1024\n",
        "model_size_mb = model_size_kb / 1024\n",
        "\n",
        "print(f\"Model size: {model_size_bytes} bytes\")\n",
        "print(f\"Model size: {model_size_kb:.2f} KB\")\n",
        "print(f\"Model size: {model_size_mb:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lqx9goek56Rq"
      },
      "id": "lqx9goek56Rq",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}